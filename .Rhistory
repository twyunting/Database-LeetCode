force = TRUE
force = TRUE
force = TRUE`
\
devtools::install_github("r-lib/devtools")
rstudioapi::isAvailable("1.2.5033")
devtools::install_github("r-lib/devtools")
devtools::install_github("r-lib/devtools")
devtools::install_github("r-lib/devtools")
devtools::install_github("r-lib/devtools")
library(devtools)
devtools::install_github("r-lib/devtools")
install_github("Stat", force=TRUE)
install_github(force=TRUE)
install_github("devtools", force=TRUE)
devtools::install_github("r-lib/devtools")
devtools::install_github("r-lib/devtools", force = TRUE)
library(devtools)
has_devel()
install.packages("available")
yes
install.packages("available")
available('ggplot2')
library(available)
available('ggplot2')
knitr::opts_chunk$set(fig.align  = "center",
fig.height = 5,
fig.width  = 6)
library(lubridate)
df %>%
mutate(data = map(data, ~pivot_longer(data = ., cols = contains("/"),
names_to = "Date",
values_to = "dailyValues"))
) -> df
knitr::opts_chunk$set(fig.align  = "center",
fig.height = 5,
fig.width  = 6)
# Installed library
library(tidyverse)
url_in <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"
df <- tibble(file_names = c("time_series_covid19_confirmed_global.csv",
"time_series_covid19_deaths_global.csv",
"time_series_covid19_confirmed_US.csv",
"time_series_covid19_deaths_US.csv")) -> df
df %>%
mutate(url = str_c(url_in, file_names, sep = "")) -> df
df %>%
mutate(data = map(url, ~read_csv(., na = ""))) -> df
df %>%
mutate(case_types = as.factor(str_extract(file_names, "[:alpha:]*_[gU][:alpha:]*"))) ->
df
# alpha = Any letter, [A-Za-z]
# reference: https://www.petefreitag.com/cheatsheets/regex/character-classes/
df %>%
select(case_types, data) -> df
df %>%
mutate(vars = map(df$data, names)) -> df
# map(df$vars, ~unlist(.)[1:15]) for checking
# a
fix_names <- function(df, pattern, rePattern){
stopifnot(is.data.frame(df), is.character(pattern), is.character(rePattern))
names(df) <- str_replace_all(names(df), pattern, rePattern)
return(df)
}
# b-f
df %>%
mutate(data = map(data, ~fix_names(., "([ey])/", "\\1_")),
data = map(data, ~fix_names(., "Admin2", "County")),
data = map(data, ~fix_names(., "Long_", "Long")),
data = map_if(data, str_detect(df$case_types, "US"),
~select(., -c("UID", "iso2", "iso3",
"code3", "FIPS", "Combined_Key"))),
data = map_if(data, str_detect(df$case_types, "global"),
~mutate(., County = "NA")),
data = map_if(data, !str_detect(df$case_types, "deaths_US"),
~mutate(., Population = 0)),
data = map(data, ~unite(., "Country_State",
c("Country_Region", "Province_State"),
remove = FALSE, na.rm = TRUE))
) -> df
# g
df %>%
mutate(vars = map(df$data, names)) -> df # synchronize the vars correspondingly
# map(df$vars, ~unlist(.)) # for checking
library(lubridate)
df %>%
mutate(data = map(data, ~pivot_longer(data = ., cols = contains("/"),
names_to = "Date",
values_to = "dailyValues"))
) -> df
df$vars <- map(df$data, names) # change the vars correspondingly
map(df$vars, ~unlist(.)) # for checking
# str(df) # check the data set
mdyCovidDate <- function(df, CovidDate){
stopifnot(is.data.frame(df), is_character(CovidDate))
df[[date]] <- mdy(df[[CovidDate]])
return(df)
}
df %>%
mutate(data = map(data, ~mdy(., "Date"))) -> df_long
str(df_long)
knitr::opts_chunk$set(echo = TRUE)
ws
# installing libraries
library(tidyverse)
library(lubridate)
# download data
ws1 <- read_csv(file = "../data/Datafiniti_Womens_Shoes_Jun19.csv")
ws2 <- read_csv(file = "../data/Datafiniti_Womens_Shoes.csv")
ws3 <- read_csv(file = "../data/7003_1.csv")
# clean and tidy
ws1 %>%
select(dateAdded, brand, categories, colors, manufacturer,
prices.amountMax, prices.color,
prices.offer, prices.size, sizes,
) -> ws1
ws2 %>%
select(dateAdded, brand, categories, colors, manufacturer,
prices.amountMax, prices.color,
prices.offer, prices.size, sizes,
) -> ws2
ws3 %>%
select(dateAdded, brand, categories, colors, manufacturer,
prices.amountMax,  prices.color,
prices.offer, prices.size, sizes,
)  %>%
mutate(prices.amountMax = as.numeric(prices.amountMax)
) -> ws3
# combined all data
ws1 %>%
bind_rows(ws2) %>%
bind_rows(ws3) -> ws
ws %>%
# convert Europe sizes to the US sizes
mutate(sizesUS = str_extract(prices.size, "\\d{1,}"),
sizesUS = recode(sizesUS, "44" = "12",
"43" = "11",
"42" = "11",
"41" = "10",
"40" = "9",
"39" = "8",
"38" = "7.5",
"37" = "6.5",
"36" = "6",
"35" = "5"),
sizesUS = as.numeric(sizesUS)) %>%
# time
separate(dateAdded, into = c("date", "time"), sep = " ") %>%
mutate(date = ymd(date),
time = hms(time),
# add discount price (% off) and calculate after discounted prices
discount = (str_extract(prices.offer, "\\d{1,}")),
discount = case_when(is.na(discount) ~ 100,
TRUE ~ as.numeric(discount)),
prices.discounted =  prices.amountMax*(discount/100)
) %>%
select(-sizes, -prices.size) %>%
rename("prices" = "prices.amountMax") -> ws
ws %>%
select(date, prices.amountMax, prices.discounted) %>%
rename("origPrices" = "prices.amountMax",
"discPrices" = "prices.discounted") %>%
mutate(Year = str_extract(date, "\\d\\d\\d\\d")) %>%
filter(!is.na(origPrices)) -> wsRegression
ws
shiny::runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
knitr::opts_chunk$set(echo = TRUE)
ws
# installing libraries
library(tidyverse)
library(lubridate)
# download data
ws1 <- read_csv(file = "../data/Datafiniti_Womens_Shoes_Jun19.csv")
ws2 <- read_csv(file = "../data/Datafiniti_Womens_Shoes.csv")
ws3 <- read_csv(file = "../data/7003_1.csv")
# clean and tidy
ws1 %>%
select(dateAdded, brand, categories, colors, manufacturer,
prices.amountMax, prices.color,
prices.offer, prices.size, sizes,
) -> ws1
ws2 %>%
select(dateAdded, brand, categories, colors, manufacturer,
prices.amountMax, prices.color,
prices.offer, prices.size, sizes,
) -> ws2
ws3 %>%
select(dateAdded, brand, categories, colors, manufacturer,
prices.amountMax,  prices.color,
prices.offer, prices.size, sizes,
)  %>%
mutate(prices.amountMax = as.numeric(prices.amountMax)
) -> ws3
# combined all data
ws1 %>%
bind_rows(ws2) %>%
bind_rows(ws3) -> ws
ws %>%
# convert Europe sizes to the US sizes
mutate(sizesUS = str_extract(prices.size, "\\d{1,}"),
sizesUS = recode(sizesUS, "44" = "12",
"43" = "11",
"42" = "11",
"41" = "10",
"40" = "9",
"39" = "8",
"38" = "7.5",
"37" = "6.5",
"36" = "6",
"35" = "5"),
sizesUS = as.numeric(sizesUS)) %>%
# time
separate(dateAdded, into = c("date", "time"), sep = " ") %>%
mutate(date = ymd(date),
time = hms(time),
# add discount price (% off) and calculate after discounted prices
discount = (str_extract(prices.offer, "\\d{1,}")),
discount = case_when(is.na(discount) ~ 100,
TRUE ~ as.numeric(discount)),
prices.discounted =  prices.amountMax*(discount/100)
) %>%
select(-sizes, -prices.size) %>%
rename("prices" = "prices.amountMax") -> ws
ws %>%
select(date, prices.amountMax, prices.discounted) %>%
rename("origPrices" = "prices.amountMax",
"discPrices" = "prices.discounted") %>%
mutate(Year = str_extract(date, "\\d\\d\\d\\d")) %>%
filter(!is.na(origPrices)) -> wsRegression
ws
str(ws)
ws
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
shiny::runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
---
title: "Food Safety in Africa"
author: "Yunting"
date: "4/30/2020"
output:
slidy_presentation:
footer: "Food Safety in Africa"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
## 1 - Team Members
* [**Yunting Chiu**](https://www.linkedin.com/in/yuntingchiu)
+ tidy data, statistical analysis, project management, data mapping, data visualization.\
* **Kingsley Ofoegbu**
+ data analysis, data-driven hypotheses, data visualization, report writing, tidy data, regression.\
* **Shan Lin**
+ report writing, literature review, data evaluation.\
* **Doudou Shi**
+ report writing, data visualization, data analysis, statistical analysis.\
## 2 - Introduction
In this project, we hope to answer certain questions with the data set we have and proffer possible solutions to bring about better Food security in Africa.\
After this, we should be able to comfortably suggest measures to counter the gaping holes in infrastructure, food supply, hazard control and questions that need answering.\
The analysis is based on Global Food Safety Partnerships (GFSP) dataset from 48 countries between 2006 to 2017. We are interested in quantitative measurement for this project, especially we compared Africa's GDP and total population.\
## 3 - Data Cleaning
### 3.1 - Loading Libraries
```{r LoadPackages, include = FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(readr)
library(ggplot2)
library(spData)
library(ggthemes)
library(sf)
library(knitr)
library(rnaturalearth)
library(rnaturalearthdata)
library(rgeos)
library(ggspatial)
library(lwgeom)
```
library(tidyverse)\
library(dplyr)\
library(readxl)\
library(readr)\
library(ggplot2)\
library(spData)\
library(ggthemes)\
library(sf)\
library(knitr)\
library(rnaturalearth)\
library(rnaturalearthdata)\
library(rgeos)\
library(ggspatial)\
library(lwgeom)\
## 3 - Data Cleaning
### 3.2 - Load the data first, and reformating features
```{r, warning=FALSE}
fsa <- read_csv(file = "./data/gfspafricamapping_final_20192.csv",
col_types = cols("Category" = col_factor(),
"A3_DonorCat" = col_factor(),
"A8_ImplCat" = col_factor(),
"A11_Yearinit" = col_number(),
"A12_YearEnd" = col_number(),
"B1_Project focus" = col_factor(),
"B2_Purpose_p" = col_factor(),
"E2_FSBudget" = col_number(),
"E3_BudgetCat" = col_factor(),
"ID number" = col_character()
), na = ".")
print(fsa,3)
```
## 3 - Data Cleaning
### 3.3 - Reshaping with multiple columns
* pivot_longer for each part.(A9, B4, C1, C3, D2, D4, D6, Running in)
* filter( != 0)
* list(factor())
* use pipe(%>%) to make connections.
```{r}
fsa %>%
pivot_longer(cols = starts_with("A9_"),names_to = "Country",names_prefix = "A9_",
values_to = "project_role", values_ptypes = list(logical())) %>%
filter(project_role !=0)->
teempA
teempA %>%
pivot_longer(cols = starts_with("B4_"),names_to = "Activity",names_prefix = "B4_Activity_",
values_to = "activity_type", values_ptypes = list(factor())) %>%
filter(activity_type !=0)->
teempB
teempB %>%
pivot_longer(cols = starts_with("C1_"),names_to = "Hazard_cat",names_prefix = "C1_HazardCat_",
values_to = "hazard_type", values_ptypes = list(factor())) %>%
filter(hazard_type !=0)->
teempC1
teempC1 %>%
pivot_longer(cols = starts_with("C3"),names_to = "Commodity_cat",
names_prefix = "C3_CommodityCat_",
values_to = "commodity_type", values_ptypes = list(factor())) %>%
filter(commodity_type !=0)->
teempC3
teempC3 %>%
pivot_longer(cols = starts_with("D2_"),names_to = "Value_chain",
names_prefix = "D2_VCPart_",
values_to = "value_part", values_ptypes = list(factor())) %>%
filter(value_part !=0)->
teempD2
teempD2 %>%
pivot_longer(cols = starts_with("D4_"),names_to = "Donor_cat",
names_prefix = "D4_DonorP_",
values_to = "Donor_part", values_ptypes = list(factor())) %>%
filter(Donor_part !=0)->
teempD4
teempD4 %>%
pivot_longer(cols = 'D6_Non-DonorP_1':'D6_Non-DonorP_9' ,names_to = "NonDonor_cat",
names_prefix = "D6_Non-DonorP_",
values_to = "NonDonor_part", values_ptypes = list(factor())) %>%
filter(NonDonor_part !=0)->
teempD6
teempD6 %>%
pivot_longer(cols = starts_with("Running in"), names_to = "Years_Ran",
names_prefix = "Running in",
values_to = "Times_Ran", values_ptypes = list(factor())) %>%
filter(Times_Ran !=0)->
fsa2
#rm(teempA, teempB, teempC1, teempC3, teempD2, teempD4, teempD6)
print(fsa2,3)
```
## 3 - Data Cleaning
### 3.4 - rename the data frame
* Country\
* B1_Project_focus\
* Total_budget_USD\
* A8_ImplCat\
* A13_TimeFrame\
* Activity\
* Commodity_cat\
* Donor_cat\
* NonDonor_cat\
```{r}
fsa2 %>%
rename(B1_Project_focus =  "B1_Project focus",
Total_budget_USD = "E1_Total_Budget",
ID_number = "ID number") %>%
mutate(A8_ImplCat = recode(A8_ImplCat,"1" = "Government",
"2" = "University",
"3" = "NGO",
"4" = "Church/faith-based",
"5" = "Public/private partnership",
"6" = "Enterprise",
"7" = "Multilateral",
"8" = "Other"),
A13_TimeFrame = recode(A13_TimeFrame,"1" = "1-4 days",
"2" = "5-14 days",
"3" = "15-30 days",
"4" = ">= 31 days"),
Activity = recode(Activity, "1" = "Research on hazards & interventions",
"2" = "Risk assessment",
"3" = "Residue sampling & testing",
"4" = "Disease surveillance",
"5" = "Legislation/policy/standards development",
"6" = "Staff training/certification",
"7" = "Regulatory compliance",
"8" = "Certification/compliance for export",
"9" = "Traceability systems",
"10" = "Extension/education/training for private sector enterprises",
"11" = "Processing facilities/equipment",
"12" = "Transport/cold-chain technology",
"13" = "Laboratory facilities/equipment",
"14" = "Laboratory methods & training",
"15" = "Private audits/certifications",
"16" = "Public awareness campaigns",
"17" = "Other technical assistance"),
Commodity_cat = recode(Commodity_cat, "1" = "Cereals",
"2" = "Legumes",
"3" = "Meat",
"4" = "Fish, crustaceans, mollusks",
"5" = "Eggs, dairy products",
"6" = "Fruits, seeds, tree nuts",
"7" = " Vegetables, roots, tubers",
"8" = "Cocoa, cocoa preparations",
"9" = "Coffee, tea, spices",
"10" = "Sugars, sugar confectionary, honey",
"11" = "Unspecified"),
Donor_cat = recode(Donor_cat, "1" = "Multilateral",
"2" = "Bilateral",
"3" = "Foundation",
"4" = "African regional",
"5" = "Industry (private only)",
"6" = "Public-private partnership",
"7" = "Development bank",
"9" = "NA"),
NonDonor_cat = recode(NonDonor_cat, "1" = "Government",
"2" = "Universities",
"3" = "NGO",
"4" = "Church/faith-based",
"5" = "Public/private partnerships",
"6" = "Enterprises",
"7" = "Other",
"9" = "NA" ),
ID_number = parse_factor(ID_number),
Country = parse_factor(Country, ordered = FALSE)) ->
fsa3
sample_n(fsa3, 10)
```
## 3 - Data Cleaning
### 3.5 - select the columns
* Country: Country name
* A8_ImplCat: Implementing organization category
* A11_YearInit: Year initiated
* A12_YearEnd: Year end
* A13_TimeFrame: Time frame of project/activity(If completed in 1 year or less)
* Activity: project activity
* Commodity_cat: Commodity category
* Donor_cat: Donor partner categories
* NonDonor_cat: Non-donor partner names
* Total_budget_USD: Total budget of project or activity (USD)
* E2_FSBudget: Estimated total budget of food safety activities (USD) within project
* Category: Category 1 and Category 2
* Hazard_cat: Hazard Category
```{r}
fsa3 %>%
select(Country,A8_ImplCat, A11_YearInit:A13_TimeFrame, Activity, Commodity_cat,
Donor_cat, NonDonor_cat, Total_budget_USD, E2_FSBudget, Category, Hazard_cat) -> fsa4
fsa4_no_dup <- fsa4[!duplicated(fsa4),]
# Country: Country name
# A8_ImplCat: Implementing organization category
# A11_YearInit: Year initiated
# A12_YearEnd: Year end
# A13_TimeFrame: Time frame of project/activity(If completed in 1 year or less)
# Activity: project activity
# Commodity_cat: Commodity category
# Donor_cat: Donor partner categories
# NonDonor_cat: Non-donor partner names
# Total_budget_USD: Total budget of project or activity (USD)
# E2_FSBudget: Estimated total budget of food safety activities (USD) within project
# Category: Category 1 and Category 2
# Hazard_cat: Hazard Category
sample_n(fsa4_no_dup,5)
```
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(dplyr)
library(readxl)
library(readr)
library(ggplot2)
library(spData)
library(ggthemes)
library(sf)
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
shiny::runApp('Google_Drive/American_University/2020_Fall/STAT-613-002_Data_Science/GitHub_STAT613/project-sales-and-branding/R')
h <- c(1,2,3,4,5)
h[length((h))]
ls(pat = "^V")
m <- matrix(c(7,9,8,6,10,12), nrow = 2, ncol = 3, byrow = T)
m[ ,3]
cells <- c91,2,3,4)
cells <- c(1,2,3,4)
aa <- matrix(cells, nrow = 2, ncol = 2, byrow = F)
aa
y <- 1:9
class(y)
dim(y)= c(3,3)
class(y)
m <- matrix(1:6,3,2)
m[, -1]
setwd("~/Google_Drive/GitHub/Database-LeetCode")
